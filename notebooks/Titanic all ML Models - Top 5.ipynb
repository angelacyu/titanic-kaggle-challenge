{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd5f2d0-8896-4dd0-ba7b-9ea578dbbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cd8711-ee5b-4c51-962f-1b8933cef5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e23e7c1-68f0-409a-8371-3fdc61bcf303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Train columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "\n",
      "First few rows of train data:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Load Kaggle Titanic dataset\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Test shape:\", test_data.shape)\n",
    "print(\"\\nTrain columns:\", train_data.columns.tolist())\n",
    "print(\"\\nFirst few rows of train data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Use training data for model comparison\n",
    "df = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400651ae-ff6a-47d0-ac9c-53204fad4f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before mapping - df columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "After mapping - df columns: ['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
      "Data shape after filtering: (891, 8)\n",
      "\n",
      "First few rows:\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked\n",
      "0         0       3    male  22.0      1      0   7.2500        S\n",
      "1         1       1  female  38.0      1      0  71.2833        C\n",
      "2         1       3  female  26.0      0      0   7.9250        S\n",
      "3         1       1  female  35.0      1      0  53.1000        S\n",
      "4         0       3    male  35.0      0      0   8.0500        S\n"
     ]
    }
   ],
   "source": [
    "# Map Kaggle column names to match your existing code\n",
    "print(\"Before mapping - df columns:\", df.columns.tolist())\n",
    "\n",
    "column_mapping = {\n",
    "    'Survived': 'survived',\n",
    "    'Pclass': 'pclass', \n",
    "    'Sex': 'sex',\n",
    "    'Age': 'age',\n",
    "    'SibSp': 'sibsp',\n",
    "    'Parch': 'parch',\n",
    "    'Fare': 'fare',\n",
    "    'Cabin': 'cabin',\n",
    "    'Embarked': 'embarked'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Keep only the columns your code needs\n",
    "df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "\n",
    "print(\"After mapping - df columns:\", df.columns.tolist())\n",
    "print(\"Data shape after filtering:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49149bc3-0318-48e4-ac7b-08bca9bc784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where target is missing\n",
    "# Would be good to count how many rows will be dropped\n",
    "df = df.dropna(subset=[\"survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11076f4f-366a-4a47-92a1-e82054e34bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "target = \"survived\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20964dd7-3921-415b-ac7d-822b9a310ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric and categorical features\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e5adc0-a9fe-43c5-b0f4-8f81d853c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
      "Categorical features: ['sex', 'embarked']\n",
      "All features: ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n"
     ]
    }
   ],
   "source": [
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"All features:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc2532c5-295d-400b-ad5a-51bbe62b7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop high-NA or irrelevant columns\n",
    "drop_cols = ['deck', 'embark_town', 'alive', 'who']\n",
    "for col in drop_cols:\n",
    "    if col in X.columns:\n",
    "        X = X.drop(columns=col)\n",
    "        if col in categorical_features:\n",
    "            categorical_features.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed5dee4d-1888-4b54-8560-86c06330196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate feature lists\n",
    "numeric_features = [col for col in numeric_features if col in X.columns]\n",
    "categorical_features = [col for col in categorical_features if col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81486595-1ba8-4408-9db2-0d41b4cb5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typically count all the N/A's before you do the preprocessing pipeline, and put a note here to say \"I replaced x values with the mean and y categorical values\"\n",
    "# For example, if you need to replace half the values, that's not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b48d7e-fe88-4185-981b-42526c8fb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "# For handling the errors because it doesn't do well with N/A or if its not imputed\n",
    "# If it's missing a value in the numeric one, then take the mean and put it in the missing value\n",
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"mean\"), StandardScaler())\n",
    "# If you're missing a value, pick the most frequent one\n",
    "categorical_transformer = make_pipeline(SimpleImputer(strategy=\"most_frequent\"), OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a847a341-8809-4af5-8991-012712402d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15dc69a2-82c1-4685-9e9c-5c1b6c376cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Dummy\", DummyClassifier()),\n",
    "    (\"LogisticRegression\", LogisticRegression(max_iter=1000)),\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"DecisionTree\", DecisionTreeClassifier()),\n",
    "    (\"RandomForest\", RandomForestClassifier()),\n",
    "    (\"GradientBoosting\", GradientBoostingClassifier()),\n",
    "    (\"SVM\", SVC(probability=True)),\n",
    "    (\"NaiveBayes\", GaussianNB()),\n",
    "    (\"MLP\", MLPClassifier(max_iter=1000)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eba9200-b20e-467b-bec7-d63e6387fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring\n",
    "scoring = {\n",
    "    \"Accuracy\": \"accuracy\",\n",
    "    \"F1\": \"f1\",\n",
    "    \"ROC-AUC\": \"roc_auc\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f17918dc-7e9f-4dfa-9912-87fa3251d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90aa9044-b177-4109-8943-4ae5048ad05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Dummy...\n",
      "Evaluating LogisticRegression...\n",
      "Evaluating KNN...\n",
      "Evaluating DecisionTree...\n",
      "Evaluating RandomForest...\n",
      "Evaluating GradientBoosting...\n",
      "Evaluating SVM...\n",
      "Evaluating NaiveBayes...\n",
      "Evaluating MLP...\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    pipeline = make_pipeline(preprocessor, model)\n",
    "    row = {\"Model\": name}\n",
    "    for metric_name, scorer in scoring.items():\n",
    "        score = cross_val_score(pipeline, X, y, cv=5, scoring=scorer)\n",
    "        row[metric_name] = np.mean(score)\n",
    "    results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135eca95-1c9b-458c-83b8-649b09acd949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance on Titanic Dataset:\n",
      "\n",
      "                Model  Accuracy        F1   ROC-AUC\n",
      "6                 SVM  0.828284  0.759580  0.850844\n",
      "5    GradientBoosting  0.822685  0.752883  0.869269\n",
      "4        RandomForest  0.818204  0.748315  0.855350\n",
      "2                 KNN  0.810345  0.740644  0.844005\n",
      "8                 MLP  0.808110  0.739896  0.853618\n",
      "7          NaiveBayes  0.789028  0.724459  0.829227\n",
      "1  LogisticRegression  0.786768  0.714376  0.849016\n",
      "3        DecisionTree  0.769964  0.693157  0.759452\n",
      "0               Dummy  0.616163  0.000000  0.500000\n"
     ]
    }
   ],
   "source": [
    "# Results DataFrame\n",
    "df_results = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False)\n",
    "print(\"\\nModel Performance on Titanic Dataset:\\n\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f550824d-1cba-4e64-8c1d-1b8c06cd6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 is precision, harmonic mean\n",
    "# Accuracy how close to the bullseye\n",
    "# ROC is area under the curve\n",
    "# The top five are very close. Can do the below steps for all 5 of those models TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e5c8e83-5bfa-48d2-8367-956f347ad888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35bc5382-d2e3-48ae-be63-67711afed729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Step 1: Reload Titanic dataset for tuning (using Kaggle data)\n",
    "# -----------------------------------------\n",
    "# Use the same Kaggle dataset that was loaded earlier\n",
    "df = train_data.copy()\n",
    "\n",
    "# Apply the same column mapping as before\n",
    "column_mapping = {\n",
    "    'Survived': 'survived',\n",
    "    'Pclass': 'pclass', \n",
    "    'Sex': 'sex',\n",
    "    'Age': 'age',\n",
    "    'SibSp': 'sibsp',\n",
    "    'Parch': 'parch',\n",
    "    'Fare': 'fare',\n",
    "    'Cabin': 'cabin',\n",
    "    'Embarked': 'embarked'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Keep only the columns needed for analysis (same as before)\n",
    "df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "\n",
    "# Drop rows where target is missing (though Kaggle train data shouldn't have missing targets)\n",
    "df = df.dropna(subset=[\"survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d015e5ca-f1c8-48c8-a247-9f55e41cf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Step 2: Feature Engineering Function\n",
    "# -----------------------------------------\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Feature: family size\n",
    "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "    df['is_alone'] = (df['family_size'] == 1).astype(int)\n",
    "\n",
    "    # Fill missing values\n",
    "    df['age'] = df['age'].fillna(df['age'].median())\n",
    "    df['fare'] = df['fare'].fillna(df['fare'].median())\n",
    "    df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    df = df.drop(columns=['class', 'who', 'deck', 'embark_town', 'alive', 'adult_male'], errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2014a9ff-7bab-4255-8c6a-1a78e9f7bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Step 3: Apply Feature Engineering\n",
    "# -----------------------------------------\n",
    "df_fe = feature_engineering(df)\n",
    "X = df_fe.drop(columns=[\"survived\"])\n",
    "y = df_fe[\"survived\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "002ab329-2660-4ac4-9081-f12f53c4c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering results:\n",
      "X shape: (891, 9)\n",
      "y shape: (891,)\n",
      "Features created: ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'family_size', 'is_alone']\n",
      "Missing values in X: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature engineering results:\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Features created:\", X.columns.tolist())\n",
    "print(\"Missing values in X:\", X.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "458becf5-c857-48e4-bd7d-14447e3245a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Step 4: Preprocessing Pipelines\n",
    "# -----------------------------------------\n",
    "numeric_features = ['age', 'fare', 'family_size']\n",
    "categorical_features = ['sex', 'embarked', 'is_alone']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "287ca147-1f18-46d5-a567-61a55cf0f1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['age', 'fare', 'family_size']\n",
      "Categorical features: ['sex', 'embarked', 'is_alone']\n",
      "All features: ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'family_size', 'is_alone']\n"
     ]
    }
   ],
   "source": [
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"All features:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cbe95e0-ea47-4bc2-9319-085de30ffdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 HYPERPARAMETER TUNING FOR TOP 5 ALGORITHMS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "📋 HOW TO USE THIS CODE:\n",
      "============================================================\n",
      "1. Make sure you have these variables defined in your notebook:\n",
      "   - train_data, test_data (your DataFrames)\n",
      "   - X_train, X_test, y_train, y_test (from train_test_split)\n",
      "   - preprocessor (your ColumnTransformer)\n",
      "\n",
      "2. Run this code:\n",
      "   results = run_complete_hyperparameter_tuning(train_data, test_data)\n",
      "\n",
      "3. Compare results:\n",
      "   comparison_df, champion = compare_tuning_results(results)\n",
      "\n",
      "4. Evaluate champion:\n",
      "   champion_model, accuracy, f1 = evaluate_champion(champion, results, X_test, y_test)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# COMPLETE HYPERPARAMETER TUNING FOR TOP 5 ALGORITHMS\n",
    "# Step 5 for all top performers: SVM, GradientBoosting, RandomForest, KNN, MLP\n",
    "# ========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 HYPERPARAMETER TUNING FOR TOP 5 ALGORITHMS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ------------------------------------------\n",
    "# PARAMETER GRIDS FOR EACH ALGORITHM\n",
    "# ------------------------------------------\n",
    "\n",
    "param_grids = {\n",
    "    'SVM': {\n",
    "        'clf__C': [0.1, 1, 10, 100],\n",
    "        'clf__kernel': ['rbf', 'linear'],\n",
    "        'clf__gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n",
    "    },\n",
    "    \n",
    "    'GradientBoosting': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__learning_rate': [0.05, 0.1, 0.2],\n",
    "        'clf__max_depth': [3, 5, 7],\n",
    "        'clf__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \n",
    "    'RandomForest': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__max_depth': [None, 10, 20, 30],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \n",
    "    'KNN': {\n",
    "        'clf__n_neighbors': [3, 5, 7, 11, 15],\n",
    "        'clf__weights': ['uniform', 'distance'],\n",
    "        'clf__metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    \n",
    "    'MLP': {\n",
    "        'clf__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "        'clf__alpha': [0.0001, 0.001, 0.01],\n",
    "        'clf__learning_rate': ['constant', 'adaptive'],\n",
    "        'clf__max_iter': [500, 1000]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ------------------------------------------\n",
    "# MODELS DICTIONARY\n",
    "# ------------------------------------------\n",
    "\n",
    "models = {\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'MLP': MLPClassifier(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# ------------------------------------------\n",
    "# TUNING FUNCTION\n",
    "# ------------------------------------------\n",
    "\n",
    "def tune_model(model_name, model, param_grid, preprocessor, X_train, y_train):\n",
    "    \"\"\"Tune a single model with GridSearchCV\"\"\"\n",
    "    \n",
    "    print(f\"\\n🔍 Tuning {model_name}...\")\n",
    "    print(f\"   Parameters to test: {len(list(param_grid.values())[0]) if param_grid else 'N/A'}\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    # Calculate total combinations\n",
    "    total_combinations = 1\n",
    "    for param_list in param_grid.values():\n",
    "        total_combinations *= len(param_list)\n",
    "    \n",
    "    print(f\"   Total combinations: {total_combinations}\")\n",
    "    \n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=5, \n",
    "        scoring='accuracy', \n",
    "        n_jobs=-1, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"   ✅ Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"   ✅ Best Parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    return grid_search\n",
    "\n",
    "# ------------------------------------------\n",
    "# MAIN EXECUTION FUNCTION\n",
    "# ------------------------------------------\n",
    "\n",
    "def run_complete_hyperparameter_tuning(train_data, test_data):\n",
    "    \"\"\"\n",
    "    Run hyperparameter tuning for all top 5 models\n",
    "    \n",
    "    Prerequisites:\n",
    "    - train_data and test_data should be loaded DataFrames\n",
    "    - feature_engineering function should be defined\n",
    "    - preprocessor should be set up\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"📊 Starting complete hyperparameter tuning process...\")\n",
    "    \n",
    "    # Results storage\n",
    "    tuning_results = {}\n",
    "    \n",
    "    # Tune each model\n",
    "    for model_name in ['SVM', 'GradientBoosting', 'RandomForest', 'KNN', 'MLP']:\n",
    "        try:\n",
    "            model = models[model_name]\n",
    "            param_grid = param_grids[model_name]\n",
    "            \n",
    "            # Tune the model\n",
    "            grid_search = tune_model(\n",
    "                model_name, \n",
    "                model, \n",
    "                param_grid, \n",
    "                preprocessor,  # This should be defined in your notebook\n",
    "                X_train,       # This should be defined in your notebook  \n",
    "                y_train        # This should be defined in your notebook\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            tuning_results[model_name] = {\n",
    "                'grid_search': grid_search,\n",
    "                'best_score': grid_search.best_score_,\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'best_estimator': grid_search.best_estimator_\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error tuning {model_name}: {str(e)}\")\n",
    "            tuning_results[model_name] = {'error': str(e)}\n",
    "    \n",
    "    return tuning_results\n",
    "\n",
    "# ------------------------------------------\n",
    "# RESULTS COMPARISON FUNCTION\n",
    "# ------------------------------------------\n",
    "\n",
    "def compare_tuning_results(results):\n",
    "    \"\"\"Compare results from all tuned models\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🏆 HYPERPARAMETER TUNING RESULTS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create comparison dataframe\n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_name, result in results.items():\n",
    "        if 'error' not in result:\n",
    "            comparison_data.append({\n",
    "                'Model': model_name,\n",
    "                'Best_CV_Score': result['best_score'],\n",
    "                'Best_Parameters': str(result['best_params'])[:100] + '...' if len(str(result['best_params'])) > 100 else str(result['best_params'])\n",
    "            })\n",
    "    \n",
    "    if comparison_data:\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df = comparison_df.sort_values('Best_CV_Score', ascending=False)\n",
    "        \n",
    "        print(\"\\nRanking after hyperparameter tuning:\")\n",
    "        print(comparison_df[['Model', 'Best_CV_Score']].to_string(index=False))\n",
    "        \n",
    "        # Find the champion\n",
    "        champion = comparison_df.iloc[0]\n",
    "        print(f\"\\n🥇 CHAMPION: {champion['Model']} with CV Score: {champion['Best_CV_Score']:.4f}\")\n",
    "        \n",
    "        return comparison_df, champion['Model']\n",
    "    else:\n",
    "        print(\"❌ No successful tuning results to compare\")\n",
    "        return None, None\n",
    "\n",
    "# ------------------------------------------\n",
    "# TEST PERFORMANCE EVALUATION\n",
    "# ------------------------------------------\n",
    "\n",
    "def evaluate_champion(champion_name, results, X_test, y_test):\n",
    "    \"\"\"Evaluate the champion model on test data\"\"\"\n",
    "    \n",
    "    if champion_name and champion_name in results:\n",
    "        print(f\"\\n🎯 EVALUATING CHAMPION: {champion_name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        champion_model = results[champion_name]['best_estimator']\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = champion_model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Test F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        print(f\"\\nDetailed Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return champion_model, accuracy, f1\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "# ------------------------------------------\n",
    "# USAGE INSTRUCTIONS\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📋 HOW TO USE THIS CODE:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. Make sure you have these variables defined in your notebook:\")\n",
    "print(\"   - train_data, test_data (your DataFrames)\")\n",
    "print(\"   - X_train, X_test, y_train, y_test (from train_test_split)\")\n",
    "print(\"   - preprocessor (your ColumnTransformer)\")\n",
    "print()\n",
    "print(\"2. Run this code:\")\n",
    "print(\"   results = run_complete_hyperparameter_tuning(train_data, test_data)\")\n",
    "print()\n",
    "print(\"3. Compare results:\")\n",
    "print(\"   comparison_df, champion = compare_tuning_results(results)\")\n",
    "print()\n",
    "print(\"4. Evaluate champion:\")\n",
    "print(\"   champion_model, accuracy, f1 = evaluate_champion(champion, results, X_test, y_test)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7520a9c8-a8c0-40d8-91c9-93be12475166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting hyperparameter tuning for all top 5 algorithms...\n",
      "This will take approximately 25-35 minutes total.\n",
      "Grab a coffee! ☕\n",
      "📊 Starting complete hyperparameter tuning process...\n",
      "\n",
      "🔍 Tuning SVM...\n",
      "   Parameters to test: 4\n",
      "   Total combinations: 48\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "   ✅ Best CV Score: 0.8300\n",
      "   ✅ Best Parameters: {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}\n",
      "\n",
      "🔍 Tuning GradientBoosting...\n",
      "   Parameters to test: 3\n",
      "   Total combinations: 81\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "   ✅ Best CV Score: 0.8300\n",
      "   ✅ Best Parameters: {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__min_samples_split': 10, 'clf__n_estimators': 50}\n",
      "\n",
      "🔍 Tuning RandomForest...\n",
      "   Parameters to test: 3\n",
      "   Total combinations: 108\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "   ✅ Best CV Score: 0.8216\n",
      "   ✅ Best Parameters: {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10, 'clf__n_estimators': 200}\n",
      "\n",
      "🔍 Tuning KNN...\n",
      "   Parameters to test: 5\n",
      "   Total combinations: 20\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "   ✅ Best CV Score: 0.8160\n",
      "   ✅ Best Parameters: {'clf__metric': 'manhattan', 'clf__n_neighbors': 15, 'clf__weights': 'uniform'}\n",
      "\n",
      "🔍 Tuning MLP...\n",
      "   Parameters to test: 4\n",
      "   Total combinations: 48\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Best CV Score: 0.8103\n",
      "   ✅ Best Parameters: {'clf__alpha': 0.001, 'clf__hidden_layer_sizes': (50,), 'clf__learning_rate': 'constant', 'clf__max_iter': 500}\n",
      "\n",
      "============================================================\n",
      "🏆 HYPERPARAMETER TUNING RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Ranking after hyperparameter tuning:\n",
      "           Model  Best_CV_Score\n",
      "GradientBoosting       0.830031\n",
      "             SVM       0.830011\n",
      "    RandomForest       0.821600\n",
      "             KNN       0.815966\n",
      "             MLP       0.810322\n",
      "\n",
      "🥇 CHAMPION: GradientBoosting with CV Score: 0.8300\n",
      "\n",
      "🎯 EVALUATING CHAMPION: GradientBoosting\n",
      "----------------------------------------\n",
      "Test Accuracy: 0.7933\n",
      "Test F1 Score: 0.7299\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       105\n",
      "           1       0.79      0.68      0.73        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# RUN THE COMPLETE HYPERPARAMETER TUNING\n",
    "# ========================================\n",
    "\n",
    "print(\"🚀 Starting hyperparameter tuning for all top 5 algorithms...\")\n",
    "print(\"This will take approximately 25-35 minutes total.\")\n",
    "print(\"Grab a coffee! ☕\")\n",
    "\n",
    "# Run the complete hyperparameter tuning\n",
    "results = run_complete_hyperparameter_tuning(train_data, test_data)\n",
    "\n",
    "# Compare all results  \n",
    "comparison_df, champion = compare_tuning_results(results)\n",
    "\n",
    "# Evaluate the champion\n",
    "champion_model, test_accuracy, test_f1 = evaluate_champion(champion, results, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34616f5f-762c-445c-a7d2-801a5f3ab72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 FINAL CHAMPION MODEL SUMMARY\n",
      "==================================================\n",
      "Champion Algorithm: GradientBoosting\n",
      "Test Accuracy: 0.7933\n",
      "Test F1 Score: 0.7299\n",
      "✅ Submission file created: titanic_champion_submission.csv\n",
      "📊 Predicted survival rate: 33.7%\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# FINAL RESULTS & SUBMISSION PREPARATION  \n",
    "# ========================================\n",
    "\n",
    "print(\"🏆 FINAL CHAMPION MODEL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Champion Algorithm: {champion}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Prepare for Kaggle submission\n",
    "if champion_model:\n",
    "    # Process test data for submission\n",
    "    test_df = test_data.rename(columns=column_mapping)\n",
    "    test_df_fe = feature_engineering(test_df)\n",
    "    \n",
    "    # Make predictions\n",
    "    final_predictions = champion_model.predict(test_df_fe.drop(columns=['survived'], errors='ignore'))\n",
    "    \n",
    "    # Create submission file\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': test_data['PassengerId'], \n",
    "        'Survived': final_predictions.astype(int)\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('titanic_champion_submission.csv', index=False)\n",
    "    print(f\"✅ Submission file created: titanic_champion_submission.csv\")\n",
    "    print(f\"📊 Predicted survival rate: {final_predictions.mean():.1%}\")\n",
    "else:\n",
    "    print(\"❌ No champion model available for submission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
