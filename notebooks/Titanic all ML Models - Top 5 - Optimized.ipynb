{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd5f2d0-8896-4dd0-ba7b-9ea578dbbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66cd8711-ee5b-4c51-962f-1b8933cef5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e23e7c1-68f0-409a-8371-3fdc61bcf303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Train columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "\n",
      "First few rows of train data:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Load Kaggle Titanic dataset\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Test shape:\", test_data.shape)\n",
    "print(\"\\nTrain columns:\", train_data.columns.tolist())\n",
    "print(\"\\nFirst few rows of train data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Use training data for model comparison\n",
    "df = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "400651ae-ff6a-47d0-ac9c-53204fad4f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before mapping - df columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "After mapping - df columns: ['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
      "Data shape after filtering: (891, 8)\n",
      "\n",
      "First few rows:\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked\n",
      "0         0       3    male  22.0      1      0   7.2500        S\n",
      "1         1       1  female  38.0      1      0  71.2833        C\n",
      "2         1       3  female  26.0      0      0   7.9250        S\n",
      "3         1       1  female  35.0      1      0  53.1000        S\n",
      "4         0       3    male  35.0      0      0   8.0500        S\n"
     ]
    }
   ],
   "source": [
    "# Map Kaggle column names to match your existing code\n",
    "print(\"Before mapping - df columns:\", df.columns.tolist())\n",
    "\n",
    "column_mapping = {\n",
    "    'Survived': 'survived',\n",
    "    'Pclass': 'pclass', \n",
    "    'Sex': 'sex',\n",
    "    'Age': 'age',\n",
    "    'SibSp': 'sibsp',\n",
    "    'Parch': 'parch',\n",
    "    'Fare': 'fare',\n",
    "    'Cabin': 'cabin',\n",
    "    'Embarked': 'embarked'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Keep only the columns your code needs\n",
    "df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "\n",
    "print(\"After mapping - df columns:\", df.columns.tolist())\n",
    "print(\"Data shape after filtering:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49149bc3-0318-48e4-ac7b-08bca9bc784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where target is missing\n",
    "# Would be good to count how many rows will be dropped\n",
    "df = df.dropna(subset=[\"survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11076f4f-366a-4a47-92a1-e82054e34bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "target = \"survived\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20964dd7-3921-415b-ac7d-822b9a310ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric and categorical features\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5e5adc0-a9fe-43c5-b0f4-8f81d853c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
      "Categorical features: ['sex', 'embarked']\n",
      "All features: ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n"
     ]
    }
   ],
   "source": [
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"All features:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2532c5-295d-400b-ad5a-51bbe62b7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop high-NA or irrelevant columns\n",
    "drop_cols = ['deck', 'embark_town', 'alive', 'who']\n",
    "for col in drop_cols:\n",
    "    if col in X.columns:\n",
    "        X = X.drop(columns=col)\n",
    "        if col in categorical_features:\n",
    "            categorical_features.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed5dee4d-1888-4b54-8560-86c06330196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate feature lists\n",
    "numeric_features = [col for col in numeric_features if col in X.columns]\n",
    "categorical_features = [col for col in categorical_features if col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81486595-1ba8-4408-9db2-0d41b4cb5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typically count all the N/A's before you do the preprocessing pipeline, and put a note here to say \"I replaced x values with the mean and y categorical values\"\n",
    "# For example, if you need to replace half the values, that's not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97b48d7e-fe88-4185-981b-42526c8fb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "# For handling the errors because it doesn't do well with N/A or if its not imputed\n",
    "# If it's missing a value in the numeric one, then take the mean and put it in the missing value\n",
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"mean\"), StandardScaler())\n",
    "# If you're missing a value, pick the most frequent one\n",
    "categorical_transformer = make_pipeline(SimpleImputer(strategy=\"most_frequent\"), OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a847a341-8809-4af5-8991-012712402d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15dc69a2-82c1-4685-9e9c-5c1b6c376cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Dummy\", DummyClassifier()),\n",
    "    (\"LogisticRegression\", LogisticRegression(max_iter=1000)),\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"DecisionTree\", DecisionTreeClassifier()),\n",
    "    (\"RandomForest\", RandomForestClassifier()),\n",
    "    (\"GradientBoosting\", GradientBoostingClassifier()),\n",
    "    (\"SVM\", SVC(probability=True)),\n",
    "    (\"NaiveBayes\", GaussianNB()),\n",
    "    (\"MLP\", MLPClassifier(max_iter=1000)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eba9200-b20e-467b-bec7-d63e6387fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring\n",
    "scoring = {\n",
    "    \"Accuracy\": \"accuracy\",\n",
    "    \"F1\": \"f1\",\n",
    "    \"ROC-AUC\": \"roc_auc\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f17918dc-7e9f-4dfa-9912-87fa3251d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90aa9044-b177-4109-8943-4ae5048ad05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Dummy...\n",
      "Evaluating LogisticRegression...\n",
      "Evaluating KNN...\n",
      "Evaluating DecisionTree...\n",
      "Evaluating RandomForest...\n",
      "Evaluating GradientBoosting...\n",
      "Evaluating SVM...\n",
      "Evaluating NaiveBayes...\n",
      "Evaluating MLP...\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    pipeline = make_pipeline(preprocessor, model)\n",
    "    row = {\"Model\": name}\n",
    "    for metric_name, scorer in scoring.items():\n",
    "        score = cross_val_score(pipeline, X, y, cv=5, scoring=scorer)\n",
    "        row[metric_name] = np.mean(score)\n",
    "    results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "135eca95-1c9b-458c-83b8-649b09acd949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance on Titanic Dataset:\n",
      "\n",
      "                Model  Accuracy        F1   ROC-AUC\n",
      "6                 SVM  0.828284  0.759580  0.850844\n",
      "5    GradientBoosting  0.822685  0.750883  0.870890\n",
      "4        RandomForest  0.818197  0.751824  0.855936\n",
      "8                 MLP  0.811474  0.745865  0.858567\n",
      "2                 KNN  0.810345  0.740644  0.844005\n",
      "7          NaiveBayes  0.789028  0.724459  0.829227\n",
      "1  LogisticRegression  0.786768  0.714376  0.849016\n",
      "3        DecisionTree  0.774452  0.690237  0.753979\n",
      "0               Dummy  0.616163  0.000000  0.500000\n"
     ]
    }
   ],
   "source": [
    "# Results DataFrame\n",
    "df_results = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False)\n",
    "print(\"\\nModel Performance on Titanic Dataset:\\n\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f550824d-1cba-4e64-8c1d-1b8c06cd6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 is precision, harmonic mean\n",
    "# Accuracy how close to the bullseye\n",
    "# ROC is area under the curve\n",
    "# The top five are very close. Can do the below steps for all 5 of those models TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e5c8e83-5bfa-48d2-8367-956f347ad888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35bc5382-d2e3-48ae-be63-67711afed729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Step 1: Reload Titanic dataset for tuning (using Kaggle data)\n",
    "# -----------------------------------------\n",
    "# Use the same Kaggle dataset that was loaded earlier\n",
    "df = train_data.copy()\n",
    "\n",
    "# Apply the same column mapping as before\n",
    "column_mapping = {\n",
    "    'Survived': 'survived',\n",
    "    'Pclass': 'pclass', \n",
    "    'Sex': 'sex',\n",
    "    'Age': 'age',\n",
    "    'SibSp': 'sibsp',\n",
    "    'Parch': 'parch',\n",
    "    'Fare': 'fare',\n",
    "    'Cabin': 'cabin',\n",
    "    'Embarked': 'embarked'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Keep only the columns needed for analysis (same as before)\n",
    "df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "\n",
    "# Drop rows where target is missing (though Kaggle train data shouldn't have missing targets)\n",
    "df = df.dropna(subset=[\"survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d015e5ca-f1c8-48c8-a247-9f55e41cf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Step 2: Feature Engineering Function\n",
    "# -----------------------------------------\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Feature: family size\n",
    "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "    df['is_alone'] = (df['family_size'] == 1).astype(int)\n",
    "\n",
    "    # Fill missing values\n",
    "    df['age'] = df['age'].fillna(df['age'].median())\n",
    "    df['fare'] = df['fare'].fillna(df['fare'].median())\n",
    "    df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    df = df.drop(columns=['class', 'who', 'deck', 'embark_town', 'alive', 'adult_male'], errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2014a9ff-7bab-4255-8c6a-1a78e9f7bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Step 3: Apply Feature Engineering\n",
    "# -----------------------------------------\n",
    "df_fe = feature_engineering(df)\n",
    "X = df_fe.drop(columns=[\"survived\"])\n",
    "y = df_fe[\"survived\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "002ab329-2660-4ac4-9081-f12f53c4c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering results:\n",
      "X shape: (891, 9)\n",
      "y shape: (891,)\n",
      "Features created: ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'family_size', 'is_alone']\n",
      "Missing values in X: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature engineering results:\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Features created:\", X.columns.tolist())\n",
    "print(\"Missing values in X:\", X.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "458becf5-c857-48e4-bd7d-14447e3245a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Step 4: Preprocessing Pipelines\n",
    "# -----------------------------------------\n",
    "numeric_features = ['age', 'fare', 'family_size']\n",
    "categorical_features = ['sex', 'embarked', 'is_alone']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "287ca147-1f18-46d5-a567-61a55cf0f1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['age', 'fare', 'family_size']\n",
      "Categorical features: ['sex', 'embarked', 'is_alone']\n",
      "All features: ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'family_size', 'is_alone']\n"
     ]
    }
   ],
   "source": [
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"All features:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cbe95e0-ea47-4bc2-9319-085de30ffdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ HYPERPARAMETER TUNING FOR TOP 5 ALGORITHMS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "üìã HOW TO USE THIS CODE:\n",
      "============================================================\n",
      "1. Make sure you have these variables defined in your notebook:\n",
      "   - train_data, test_data (your DataFrames)\n",
      "   - X_train, X_test, y_train, y_test (from train_test_split)\n",
      "   - preprocessor (your ColumnTransformer)\n",
      "\n",
      "2. Run this code:\n",
      "   results = run_complete_hyperparameter_tuning(train_data, test_data)\n",
      "\n",
      "3. Compare results:\n",
      "   comparison_df, champion = compare_tuning_results(results)\n",
      "\n",
      "4. Evaluate champion:\n",
      "   champion_model, accuracy, f1 = evaluate_champion(champion, results, X_test, y_test)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# COMPLETE HYPERPARAMETER TUNING FOR TOP 5 ALGORITHMS\n",
    "# Step 5 for all top performers: SVM, GradientBoosting, RandomForest, KNN, MLP\n",
    "# ========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ HYPERPARAMETER TUNING FOR TOP 5 ALGORITHMS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ------------------------------------------\n",
    "# PARAMETER GRIDS FOR EACH ALGORITHM\n",
    "# ------------------------------------------\n",
    "\n",
    "param_grids = {\n",
    "    'SVM': {\n",
    "        'clf__C': [0.1, 1, 10, 100],\n",
    "        'clf__kernel': ['rbf', 'linear'],\n",
    "        'clf__gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n",
    "    },\n",
    "    \n",
    "    'GradientBoosting': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__learning_rate': [0.05, 0.1, 0.2],\n",
    "        'clf__max_depth': [3, 5, 7],\n",
    "        'clf__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \n",
    "    'RandomForest': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__max_depth': [None, 10, 20, 30],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \n",
    "    'KNN': {\n",
    "        'clf__n_neighbors': [3, 5, 7, 11, 15],\n",
    "        'clf__weights': ['uniform', 'distance'],\n",
    "        'clf__metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    \n",
    "    'MLP': {\n",
    "        'clf__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "        'clf__alpha': [0.0001, 0.001, 0.01],\n",
    "        'clf__learning_rate': ['constant', 'adaptive'],\n",
    "        'clf__max_iter': [500, 1000]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ------------------------------------------\n",
    "# MODELS DICTIONARY\n",
    "# ------------------------------------------\n",
    "\n",
    "models = {\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'MLP': MLPClassifier(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# ------------------------------------------\n",
    "# TUNING FUNCTION\n",
    "# ------------------------------------------\n",
    "\n",
    "def tune_model(model_name, model, param_grid, preprocessor, X_train, y_train):\n",
    "    \"\"\"Tune a single model with GridSearchCV\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç Tuning {model_name}...\")\n",
    "    print(f\"   Parameters to test: {len(list(param_grid.values())[0]) if param_grid else 'N/A'}\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    # Calculate total combinations\n",
    "    total_combinations = 1\n",
    "    for param_list in param_grid.values():\n",
    "        total_combinations *= len(param_list)\n",
    "    \n",
    "    print(f\"   Total combinations: {total_combinations}\")\n",
    "    \n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=5, \n",
    "        scoring='accuracy', \n",
    "        n_jobs=-1, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"   ‚úÖ Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"   ‚úÖ Best Parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    return grid_search\n",
    "\n",
    "# ------------------------------------------\n",
    "# MAIN EXECUTION FUNCTION\n",
    "# ------------------------------------------\n",
    "\n",
    "def run_complete_hyperparameter_tuning(train_data, test_data):\n",
    "    \"\"\"\n",
    "    Run hyperparameter tuning for all top 5 models\n",
    "    \n",
    "    Prerequisites:\n",
    "    - train_data and test_data should be loaded DataFrames\n",
    "    - feature_engineering function should be defined\n",
    "    - preprocessor should be set up\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìä Starting complete hyperparameter tuning process...\")\n",
    "    \n",
    "    # Results storage\n",
    "    tuning_results = {}\n",
    "    \n",
    "    # Tune each model\n",
    "    for model_name in ['SVM', 'GradientBoosting', 'RandomForest', 'KNN', 'MLP']:\n",
    "        try:\n",
    "            model = models[model_name]\n",
    "            param_grid = param_grids[model_name]\n",
    "            \n",
    "            # Tune the model\n",
    "            grid_search = tune_model(\n",
    "                model_name, \n",
    "                model, \n",
    "                param_grid, \n",
    "                preprocessor,  # This should be defined in your notebook\n",
    "                X_train,       # This should be defined in your notebook  \n",
    "                y_train        # This should be defined in your notebook\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            tuning_results[model_name] = {\n",
    "                'grid_search': grid_search,\n",
    "                'best_score': grid_search.best_score_,\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'best_estimator': grid_search.best_estimator_\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error tuning {model_name}: {str(e)}\")\n",
    "            tuning_results[model_name] = {'error': str(e)}\n",
    "    \n",
    "    return tuning_results\n",
    "\n",
    "# ------------------------------------------\n",
    "# RESULTS COMPARISON FUNCTION\n",
    "# ------------------------------------------\n",
    "\n",
    "def compare_tuning_results(results):\n",
    "    \"\"\"Compare results from all tuned models\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üèÜ HYPERPARAMETER TUNING RESULTS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create comparison dataframe\n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_name, result in results.items():\n",
    "        if 'error' not in result:\n",
    "            comparison_data.append({\n",
    "                'Model': model_name,\n",
    "                'Best_CV_Score': result['best_score'],\n",
    "                'Best_Parameters': str(result['best_params'])[:100] + '...' if len(str(result['best_params'])) > 100 else str(result['best_params'])\n",
    "            })\n",
    "    \n",
    "    if comparison_data:\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df = comparison_df.sort_values('Best_CV_Score', ascending=False)\n",
    "        \n",
    "        print(\"\\nRanking after hyperparameter tuning:\")\n",
    "        print(comparison_df[['Model', 'Best_CV_Score']].to_string(index=False))\n",
    "        \n",
    "        # Find the champion\n",
    "        champion = comparison_df.iloc[0]\n",
    "        print(f\"\\nü•á CHAMPION: {champion['Model']} with CV Score: {champion['Best_CV_Score']:.4f}\")\n",
    "        \n",
    "        return comparison_df, champion['Model']\n",
    "    else:\n",
    "        print(\"‚ùå No successful tuning results to compare\")\n",
    "        return None, None\n",
    "\n",
    "# ------------------------------------------\n",
    "# TEST PERFORMANCE EVALUATION\n",
    "# ------------------------------------------\n",
    "\n",
    "def evaluate_champion(champion_name, results, X_test, y_test):\n",
    "    \"\"\"Evaluate the champion model on test data\"\"\"\n",
    "    \n",
    "    if champion_name and champion_name in results:\n",
    "        print(f\"\\nüéØ EVALUATING CHAMPION: {champion_name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        champion_model = results[champion_name]['best_estimator']\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = champion_model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Test F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        print(f\"\\nDetailed Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return champion_model, accuracy, f1\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "# ------------------------------------------\n",
    "# USAGE INSTRUCTIONS\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã HOW TO USE THIS CODE:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. Make sure you have these variables defined in your notebook:\")\n",
    "print(\"   - train_data, test_data (your DataFrames)\")\n",
    "print(\"   - X_train, X_test, y_train, y_test (from train_test_split)\")\n",
    "print(\"   - preprocessor (your ColumnTransformer)\")\n",
    "print()\n",
    "print(\"2. Run this code:\")\n",
    "print(\"   results = run_complete_hyperparameter_tuning(train_data, test_data)\")\n",
    "print()\n",
    "print(\"3. Compare results:\")\n",
    "print(\"   comparison_df, champion = compare_tuning_results(results)\")\n",
    "print()\n",
    "print(\"4. Evaluate champion:\")\n",
    "print(\"   champion_model, accuracy, f1 = evaluate_champion(champion, results, X_test, y_test)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7520a9c8-a8c0-40d8-91c9-93be12475166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting hyperparameter tuning for all top 5 algorithms...\n",
      "This will take approximately 25-35 minutes total.\n",
      "Grab a coffee! ‚òï\n",
      "üìä Starting complete hyperparameter tuning process...\n",
      "\n",
      "üîç Tuning SVM...\n",
      "   Parameters to test: 4\n",
      "   Total combinations: 48\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "   ‚úÖ Best CV Score: 0.8300\n",
      "   ‚úÖ Best Parameters: {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}\n",
      "\n",
      "üîç Tuning GradientBoosting...\n",
      "   Parameters to test: 3\n",
      "   Total combinations: 81\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "   ‚úÖ Best CV Score: 0.8300\n",
      "   ‚úÖ Best Parameters: {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__min_samples_split': 10, 'clf__n_estimators': 50}\n",
      "\n",
      "üîç Tuning RandomForest...\n",
      "   Parameters to test: 3\n",
      "   Total combinations: 108\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "   ‚úÖ Best CV Score: 0.8216\n",
      "   ‚úÖ Best Parameters: {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10, 'clf__n_estimators': 200}\n",
      "\n",
      "üîç Tuning KNN...\n",
      "   Parameters to test: 5\n",
      "   Total combinations: 20\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "   ‚úÖ Best CV Score: 0.8160\n",
      "   ‚úÖ Best Parameters: {'clf__metric': 'manhattan', 'clf__n_neighbors': 15, 'clf__weights': 'uniform'}\n",
      "\n",
      "üîç Tuning MLP...\n",
      "   Parameters to test: 4\n",
      "   Total combinations: 48\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Best CV Score: 0.8103\n",
      "   ‚úÖ Best Parameters: {'clf__alpha': 0.001, 'clf__hidden_layer_sizes': (50,), 'clf__learning_rate': 'constant', 'clf__max_iter': 500}\n",
      "\n",
      "============================================================\n",
      "üèÜ HYPERPARAMETER TUNING RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Ranking after hyperparameter tuning:\n",
      "           Model  Best_CV_Score\n",
      "GradientBoosting       0.830031\n",
      "             SVM       0.830011\n",
      "    RandomForest       0.821600\n",
      "             KNN       0.815966\n",
      "             MLP       0.810322\n",
      "\n",
      "ü•á CHAMPION: GradientBoosting with CV Score: 0.8300\n",
      "\n",
      "üéØ EVALUATING CHAMPION: GradientBoosting\n",
      "----------------------------------------\n",
      "Test Accuracy: 0.7933\n",
      "Test F1 Score: 0.7299\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       105\n",
      "           1       0.79      0.68      0.73        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# RUN THE COMPLETE HYPERPARAMETER TUNING\n",
    "# ========================================\n",
    "\n",
    "print(\"üöÄ Starting hyperparameter tuning for all top 5 algorithms...\")\n",
    "print(\"This will take approximately 25-35 minutes total.\")\n",
    "print(\"Grab a coffee! ‚òï\")\n",
    "\n",
    "# Run the complete hyperparameter tuning\n",
    "results = run_complete_hyperparameter_tuning(train_data, test_data)\n",
    "\n",
    "# Compare all results  \n",
    "comparison_df, champion = compare_tuning_results(results)\n",
    "\n",
    "# Evaluate the champion\n",
    "champion_model, test_accuracy, test_f1 = evaluate_champion(champion, results, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90ddea15-7a1f-4a03-8ed1-311d80d50085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DEEP ANALYSIS: WHY GRADIENTBOOSTING EMERGED AS CHAMPION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üìã TO RUN THIS ANALYSIS:\n",
      "======================================================================\n",
      "Run this code after your hyperparameter tuning:\n",
      "\n",
      "feature_imp, best_params = analyze_champion_performance(\n",
      "    champion_model, results, X_test, y_test, X_train, y_train)\n",
      "\n",
      "model_names, scores = create_performance_visualizations(results)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# DEEP ANALYSIS: WHY GRADIENTBOOSTING WON\n",
    "# ========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üîç DEEP ANALYSIS: WHY GRADIENTBOOSTING EMERGED AS CHAMPION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def analyze_champion_performance(champion_model, results, X_test, y_test, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of why GradientBoosting won over other algorithms\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================\n",
    "    # 1. ALGORITHM CHARACTERISTICS ANALYSIS\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\\n1Ô∏è‚É£ ALGORITHM CHARACTERISTICS COMPARISON\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    algorithm_strengths = {\n",
    "        'GradientBoosting': [\n",
    "            '‚úÖ Handles mixed data types well (numerical + categorical)',\n",
    "            '‚úÖ Robust to outliers and missing values', \n",
    "            '‚úÖ Captures non-linear patterns effectively',\n",
    "            '‚úÖ Built-in regularization prevents overfitting',\n",
    "            '‚úÖ Sequential learning corrects previous mistakes',\n",
    "            '‚úÖ Great for tabular data like Titanic dataset'\n",
    "        ],\n",
    "        'SVM': [\n",
    "            '‚ùå Struggles with mixed categorical/numerical data',\n",
    "            '‚ùå Sensitive to feature scaling (despite preprocessing)',\n",
    "            '‚ùå Limited interpretability',\n",
    "            '‚ùå Can overfit on small datasets'\n",
    "        ],\n",
    "        'RandomForest': [\n",
    "            '‚ö†Ô∏è Can overfit with too many trees',\n",
    "            '‚ö†Ô∏è Biased toward features with more levels',\n",
    "            '‚ö†Ô∏è Less effective than boosting on small datasets'\n",
    "        ],\n",
    "        'KNN': [\n",
    "            '‚ùå Curse of dimensionality with many features',\n",
    "            '‚ùå Sensitive to irrelevant features',\n",
    "            '‚ùå Poor performance with imbalanced classes'\n",
    "        ],\n",
    "        'MLP': [\n",
    "            '‚ùå Needs much more data to perform well',\n",
    "            '‚ùå Prone to overfitting on small datasets (891 samples)',\n",
    "            '‚ùå Convergence issues (those warnings you saw!)',\n",
    "            '‚ùå Requires extensive hyperparameter tuning'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"üèÜ Why GradientBoosting excelled:\")\n",
    "    for strength in algorithm_strengths['GradientBoosting']:\n",
    "        print(f\"   {strength}\")\n",
    "    \n",
    "    print(\"\\nüí° Why others fell short:\")\n",
    "    for algo, weaknesses in algorithm_strengths.items():\n",
    "        if algo != 'GradientBoosting':\n",
    "            print(f\"\\n   {algo}:\")\n",
    "            for weakness in weaknesses:\n",
    "                print(f\"     {weakness}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 2. TITANIC DATASET CHARACTERISTICS\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n\\n2Ô∏è‚É£ TITANIC DATASET CHARACTERISTICS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"üìä Dataset Properties that favor GradientBoosting:\")\n",
    "    print(\"   ‚Ä¢ Small dataset (891 samples) - boosting works well\")\n",
    "    print(\"   ‚Ä¢ Mixed data types (age, fare, sex, embarked) - GB handles naturally\")\n",
    "    print(\"   ‚Ä¢ Non-linear relationships (e.g., age*class interaction)\")\n",
    "    print(\"   ‚Ä¢ Missing values - GB robust to them\")\n",
    "    print(\"   ‚Ä¢ Class imbalance (62% died, 38% survived) - GB handles well\")\n",
    "    print(\"   ‚Ä¢ Feature interactions matter (women+1st class = high survival)\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 3. PERFORMANCE METRICS DEEP DIVE\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n\\n3Ô∏è‚É£ PERFORMANCE METRICS ANALYSIS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get predictions from champion\n",
    "    y_pred = champion_model.predict(X_test)\n",
    "    y_pred_proba = champion_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Confusion Matrix Analysis\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(\"üéØ Confusion Matrix Analysis:\")\n",
    "    print(f\"   True Negatives (Correctly predicted deaths): {cm[0,0]}\")\n",
    "    print(f\"   False Positives (Incorrectly predicted survival): {cm[0,1]}\")\n",
    "    print(f\"   False Negatives (Missed survivors): {cm[1,0]}\")\n",
    "    print(f\"   True Positives (Correctly predicted survivors): {cm[1,1]}\")\n",
    "    \n",
    "    # Calculate precision, recall, specificity\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    print(f\"\\nüìà Key Metrics:\")\n",
    "    print(f\"   Precision (of predicted survivors, % actually survived): {precision:.3f}\")\n",
    "    print(f\"   Recall (% of actual survivors we caught): {recall:.3f}\")\n",
    "    print(f\"   Specificity (% of deaths correctly identified): {specificity:.3f}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 4. FEATURE IMPORTANCE ANALYSIS\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n\\n4Ô∏è‚É£ FEATURE IMPORTANCE ANALYSIS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get feature importance from the GradientBoosting model\n",
    "    # Extract the classifier from the pipeline\n",
    "    gb_classifier = champion_model.named_steps['clf']\n",
    "    feature_importance = gb_classifier.feature_importances_\n",
    "    \n",
    "    # Get feature names (this is tricky with pipelines, so we'll estimate)\n",
    "    print(\"üîç Top Features GradientBoosting Found Important:\")\n",
    "    print(\"   (Note: Exact feature names depend on preprocessing pipeline)\")\n",
    "    \n",
    "    # We know the general structure from our preprocessing\n",
    "    estimated_features = [\n",
    "        'age', 'fare', 'family_size',  # numeric features\n",
    "        'sex_female', 'sex_male',      # sex encoding\n",
    "        'embarked_C', 'embarked_Q', 'embarked_S',  # embarked encoding  \n",
    "        'is_alone_0', 'is_alone_1'     # is_alone encoding\n",
    "    ]\n",
    "    \n",
    "    if len(feature_importance) >= len(estimated_features):\n",
    "        feature_df = pd.DataFrame({\n",
    "            'feature': estimated_features[:len(feature_importance)],\n",
    "            'importance': feature_importance[:len(estimated_features)]\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(\"   Top 5 Most Important Features:\")\n",
    "        for i, row in feature_df.head().iterrows():\n",
    "            print(f\"     {row['feature']}: {row['importance']:.3f}\")\n",
    "    else:\n",
    "        print(\"   Feature importance available but names need mapping\")\n",
    "        top_5_importance = sorted(feature_importance, reverse=True)[:5]\n",
    "        for i, imp in enumerate(top_5_importance):\n",
    "            print(f\"     Feature {i+1}: {imp:.3f}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 5. MODEL COMPLEXITY ANALYSIS\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n\\n5Ô∏è‚É£ MODEL COMPLEXITY & GENERALIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Extract best parameters\n",
    "    best_params = results['GradientBoosting']['best_params']\n",
    "    print(\"üéõÔ∏è Optimal Hyperparameters Found:\")\n",
    "    for param, value in best_params.items():\n",
    "        param_name = param.replace('clf__', '')\n",
    "        print(f\"   {param_name}: {value}\")\n",
    "    \n",
    "    print(f\"\\nüß† Why these parameters work:\")\n",
    "    \n",
    "    # Analyze key parameters\n",
    "    if 'clf__n_estimators' in best_params:\n",
    "        n_est = best_params['clf__n_estimators']\n",
    "        print(f\"   ‚Ä¢ n_estimators={n_est}: Enough trees to learn patterns, not too many to overfit\")\n",
    "    \n",
    "    if 'clf__learning_rate' in best_params:\n",
    "        lr = best_params['clf__learning_rate']\n",
    "        print(f\"   ‚Ä¢ learning_rate={lr}: {'Conservative' if lr <= 0.1 else 'Moderate'} learning prevents overfitting\")\n",
    "    \n",
    "    if 'clf__max_depth' in best_params:\n",
    "        depth = best_params['clf__max_depth']\n",
    "        print(f\"   ‚Ä¢ max_depth={depth}: {'Shallow' if depth <= 3 else 'Moderate'} trees prevent overfitting\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 6. COMPARISON WITH ORIGINAL SCORES\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n\\n6Ô∏è‚É£ IMPROVEMENT FROM HYPERPARAMETER TUNING\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    original_scores = {\n",
    "        'SVM': 0.8283,\n",
    "        'GradientBoosting': 0.8227, \n",
    "        'RandomForest': 0.8126,\n",
    "        'KNN': 0.8103,\n",
    "        'MLP': 0.8003\n",
    "    }\n",
    "    \n",
    "    tuned_score = results['GradientBoosting']['best_score']\n",
    "    original_score = original_scores['GradientBoosting']\n",
    "    \n",
    "    print(f\"üìä GradientBoosting Performance:\")\n",
    "    print(f\"   Before tuning (default params): {original_score:.4f}\")\n",
    "    print(f\"   After tuning (optimized params): {tuned_score:.4f}\")\n",
    "    print(f\"   Improvement: {tuned_score - original_score:+.4f}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ Ranking Changes:\")\n",
    "    print(f\"   Original ranking: #2 (behind SVM)\")\n",
    "    print(f\"   After tuning: #1 (Champion!)\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 7. BUSINESS IMPACT ANALYSIS\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n\\n7Ô∏è‚É£ BUSINESS IMPACT & INTERPRETABILITY\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"üíº Why GradientBoosting makes business sense:\")\n",
    "    print(\"   ‚úÖ Interpretable feature importance (can explain to stakeholders)\")\n",
    "    print(\"   ‚úÖ Robust predictions (consistent performance)\")\n",
    "    print(\"   ‚úÖ Handles real-world messy data well\")\n",
    "    print(\"   ‚úÖ Can identify key survival factors for safety improvements\")\n",
    "    \n",
    "    survival_rate_pred = y_pred.mean()\n",
    "    actual_survival_rate = y_test.mean()\n",
    "    \n",
    "    print(f\"\\nüìà Prediction Calibration:\")\n",
    "    print(f\"   Actual survival rate in test set: {actual_survival_rate:.1%}\")\n",
    "    print(f\"   Predicted survival rate: {survival_rate_pred:.1%}\")\n",
    "    print(f\"   Difference: {abs(survival_rate_pred - actual_survival_rate):.1%} (closer = better calibrated)\")\n",
    "    \n",
    "    return feature_importance, best_params\n",
    "\n",
    "# ========================================\n",
    "# VISUALIZATION FUNCTION\n",
    "# ========================================\n",
    "\n",
    "def create_performance_visualizations(results):\n",
    "    \"\"\"Create visualizations comparing all algorithms\"\"\"\n",
    "    \n",
    "    print(f\"\\n\\n8Ô∏è‚É£ VISUAL PERFORMANCE COMPARISON\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Extract scores for plotting\n",
    "    model_names = []\n",
    "    cv_scores = []\n",
    "    \n",
    "    for model_name, result in results.items():\n",
    "        if 'error' not in result:\n",
    "            model_names.append(model_name)\n",
    "            cv_scores.append(result['best_score'])\n",
    "    \n",
    "    if len(model_names) > 0:\n",
    "        # Create performance comparison plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Subplot 1: CV Scores\n",
    "        plt.subplot(1, 2, 1)\n",
    "        colors = ['gold' if name == 'GradientBoosting' else 'lightblue' for name in model_names]\n",
    "        bars = plt.bar(model_names, cv_scores, color=colors)\n",
    "        plt.title('Cross-Validation Scores\\n(After Hyperparameter Tuning)', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('CV Accuracy Score')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, score in zip(bars, cv_scores):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "                    f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # Highlight the champion\n",
    "        champion_idx = cv_scores.index(max(cv_scores))\n",
    "        bars[champion_idx].set_edgecolor('red')\n",
    "        bars[champion_idx].set_linewidth(3)\n",
    "        \n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Subplot 2: Improvement from baseline\n",
    "        plt.subplot(1, 2, 2)\n",
    "        original_scores = [0.8283, 0.8227, 0.8126, 0.8103, 0.8003]  # Original scores\n",
    "        improvements = [cv - orig for cv, orig in zip(cv_scores, original_scores[:len(cv_scores)])]\n",
    "        \n",
    "        colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
    "        colors = ['gold' if name == 'GradientBoosting' else color for name, color in zip(model_names, colors)]\n",
    "        \n",
    "        bars2 = plt.bar(model_names, improvements, color=colors, alpha=0.7)\n",
    "        plt.title('Improvement from\\nHyperparameter Tuning', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Score Improvement')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, imp in zip(bars2, improvements):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, \n",
    "                    bar.get_height() + (0.002 if imp > 0 else -0.005), \n",
    "                    f'{imp:+.3f}', ha='center', \n",
    "                    va='bottom' if imp > 0 else 'top', fontweight='bold')\n",
    "        \n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"üìä Visualization shows:\")\n",
    "        print(f\"   ü•á GradientBoosting achieved highest CV score: {max(cv_scores):.4f}\")\n",
    "        print(f\"   üìà Best improvement from tuning: {max(improvements):+.4f}\")\n",
    "    \n",
    "    return model_names, cv_scores\n",
    "\n",
    "# ========================================\n",
    "# USAGE INSTRUCTIONS\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã TO RUN THIS ANALYSIS:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Run this code after your hyperparameter tuning:\")\n",
    "print()\n",
    "print(\"feature_imp, best_params = analyze_champion_performance(\")\n",
    "print(\"    champion_model, results, X_test, y_test, X_train, y_train)\")\n",
    "print()\n",
    "print(\"model_names, scores = create_performance_visualizations(results)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1451a6cf-2622-47dc-b0c7-41bdfbcc8c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Running the deep analysis...\n",
      "\n",
      "1Ô∏è‚É£ ALGORITHM CHARACTERISTICS COMPARISON\n",
      "--------------------------------------------------\n",
      "üèÜ Why GradientBoosting excelled:\n",
      "   ‚úÖ Handles mixed data types well (numerical + categorical)\n",
      "   ‚úÖ Robust to outliers and missing values\n",
      "   ‚úÖ Captures non-linear patterns effectively\n",
      "   ‚úÖ Built-in regularization prevents overfitting\n",
      "   ‚úÖ Sequential learning corrects previous mistakes\n",
      "   ‚úÖ Great for tabular data like Titanic dataset\n",
      "\n",
      "üí° Why others fell short:\n",
      "\n",
      "   SVM:\n",
      "     ‚ùå Struggles with mixed categorical/numerical data\n",
      "     ‚ùå Sensitive to feature scaling (despite preprocessing)\n",
      "     ‚ùå Limited interpretability\n",
      "     ‚ùå Can overfit on small datasets\n",
      "\n",
      "   RandomForest:\n",
      "     ‚ö†Ô∏è Can overfit with too many trees\n",
      "     ‚ö†Ô∏è Biased toward features with more levels\n",
      "     ‚ö†Ô∏è Less effective than boosting on small datasets\n",
      "\n",
      "   KNN:\n",
      "     ‚ùå Curse of dimensionality with many features\n",
      "     ‚ùå Sensitive to irrelevant features\n",
      "     ‚ùå Poor performance with imbalanced classes\n",
      "\n",
      "   MLP:\n",
      "     ‚ùå Needs much more data to perform well\n",
      "     ‚ùå Prone to overfitting on small datasets (891 samples)\n",
      "     ‚ùå Convergence issues (those warnings you saw!)\n",
      "     ‚ùå Requires extensive hyperparameter tuning\n",
      "\n",
      "\n",
      "2Ô∏è‚É£ TITANIC DATASET CHARACTERISTICS\n",
      "--------------------------------------------------\n",
      "üìä Dataset Properties that favor GradientBoosting:\n",
      "   ‚Ä¢ Small dataset (891 samples) - boosting works well\n",
      "   ‚Ä¢ Mixed data types (age, fare, sex, embarked) - GB handles naturally\n",
      "   ‚Ä¢ Non-linear relationships (e.g., age*class interaction)\n",
      "   ‚Ä¢ Missing values - GB robust to them\n",
      "   ‚Ä¢ Class imbalance (62% died, 38% survived) - GB handles well\n",
      "   ‚Ä¢ Feature interactions matter (women+1st class = high survival)\n",
      "\n",
      "\n",
      "3Ô∏è‚É£ PERFORMANCE METRICS ANALYSIS\n",
      "--------------------------------------------------\n",
      "üéØ Confusion Matrix Analysis:\n",
      "   True Negatives (Correctly predicted deaths): 92\n",
      "   False Positives (Incorrectly predicted survival): 13\n",
      "   False Negatives (Missed survivors): 24\n",
      "   True Positives (Correctly predicted survivors): 50\n",
      "\n",
      "üìà Key Metrics:\n",
      "   Precision (of predicted survivors, % actually survived): 0.794\n",
      "   Recall (% of actual survivors we caught): 0.676\n",
      "   Specificity (% of deaths correctly identified): 0.876\n",
      "\n",
      "\n",
      "4Ô∏è‚É£ FEATURE IMPORTANCE ANALYSIS\n",
      "--------------------------------------------------\n",
      "üîç Top Features GradientBoosting Found Important:\n",
      "   (Note: Exact feature names depend on preprocessing pipeline)\n",
      "   Top 5 Most Important Features:\n",
      "     sex_female: 0.315\n",
      "     sex_male: 0.263\n",
      "     fare: 0.190\n",
      "     family_size: 0.138\n",
      "     age: 0.086\n",
      "\n",
      "\n",
      "5Ô∏è‚É£ MODEL COMPLEXITY & GENERALIZATION\n",
      "--------------------------------------------------\n",
      "üéõÔ∏è Optimal Hyperparameters Found:\n",
      "   learning_rate: 0.05\n",
      "   max_depth: 3\n",
      "   min_samples_split: 10\n",
      "   n_estimators: 50\n",
      "\n",
      "üß† Why these parameters work:\n",
      "   ‚Ä¢ n_estimators=50: Enough trees to learn patterns, not too many to overfit\n",
      "   ‚Ä¢ learning_rate=0.05: Conservative learning prevents overfitting\n",
      "   ‚Ä¢ max_depth=3: Shallow trees prevent overfitting\n",
      "\n",
      "\n",
      "6Ô∏è‚É£ IMPROVEMENT FROM HYPERPARAMETER TUNING\n",
      "--------------------------------------------------\n",
      "üìä GradientBoosting Performance:\n",
      "   Before tuning (default params): 0.8227\n",
      "   After tuning (optimized params): 0.8300\n",
      "   Improvement: +0.0073\n",
      "\n",
      "üèÜ Ranking Changes:\n",
      "   Original ranking: #2 (behind SVM)\n",
      "   After tuning: #1 (Champion!)\n",
      "\n",
      "\n",
      "7Ô∏è‚É£ BUSINESS IMPACT & INTERPRETABILITY\n",
      "--------------------------------------------------\n",
      "üíº Why GradientBoosting makes business sense:\n",
      "   ‚úÖ Interpretable feature importance (can explain to stakeholders)\n",
      "   ‚úÖ Robust predictions (consistent performance)\n",
      "   ‚úÖ Handles real-world messy data well\n",
      "   ‚úÖ Can identify key survival factors for safety improvements\n",
      "\n",
      "üìà Prediction Calibration:\n",
      "   Actual survival rate in test set: 41.3%\n",
      "   Predicted survival rate: 35.2%\n",
      "   Difference: 6.1% (closer = better calibrated)\n",
      "\n",
      "\n",
      "8Ô∏è‚É£ VISUAL PERFORMANCE COMPARISON\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Visualization shows:\n",
      "   ü•á GradientBoosting achieved highest CV score: 0.8300\n",
      "   üìà Best improvement from tuning: +0.0100\n",
      "\n",
      "‚úÖ Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# RUN THE DEEP ANALYSIS\n",
    "# ========================================\n",
    "\n",
    "print(\"üîç Running the deep analysis...\")\n",
    "\n",
    "# Run the champion performance analysis\n",
    "feature_imp, best_params = analyze_champion_performance(\n",
    "    champion_model, results, X_test, y_test, X_train, y_train)\n",
    "\n",
    "# Create the performance visualizations\n",
    "model_names, scores = create_performance_visualizations(results)\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34616f5f-762c-445c-a7d2-801a5f3ab72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ FINAL CHAMPION MODEL SUMMARY\n",
      "==================================================\n",
      "Champion Algorithm: GradientBoosting\n",
      "Test Accuracy: 0.7933\n",
      "Test F1 Score: 0.7299\n",
      "‚úÖ Submission file created: titanic_champion_submission.csv\n",
      "üìä Predicted survival rate: 33.7%\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# FINAL RESULTS & SUBMISSION PREPARATION  \n",
    "# ========================================\n",
    "\n",
    "print(\"üèÜ FINAL CHAMPION MODEL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Champion Algorithm: {champion}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Prepare for Kaggle submission\n",
    "if champion_model:\n",
    "    # Process test data for submission\n",
    "    test_df = test_data.rename(columns=column_mapping)\n",
    "    test_df_fe = feature_engineering(test_df)\n",
    "    \n",
    "    # Make predictions\n",
    "    final_predictions = champion_model.predict(test_df_fe.drop(columns=['survived'], errors='ignore'))\n",
    "    \n",
    "    # Create submission file\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': test_data['PassengerId'], \n",
    "        'Survived': final_predictions.astype(int)\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('titanic_champion_submission.csv', index=False)\n",
    "    print(f\"‚úÖ Submission file created: titanic_champion_submission.csv\")\n",
    "    print(f\"üìä Predicted survival rate: {final_predictions.mean():.1%}\")\n",
    "else:\n",
    "    print(\"‚ùå No champion model available for submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e2a4f74-7568-4c62-a1e8-80b582f48d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ FIXED ADVANCED OPTIMIZATION FOR KAGGLE LEADERBOARD\n",
      "Target: Push from 79% to 82-85% accuracy\n",
      "============================================================\n",
      "üöÄ Starting Quick Advanced Optimization...\n",
      "This will take 5-10 minutes and should improve your score!\n",
      "\n",
      "üöÄ RUNNING QUICK OPTIMIZATION\n",
      "==================================================\n",
      "üìä Processing data...\n",
      "üîß Creating advanced features...\n",
      "   ‚úÖ Created 28 total features\n",
      "üîß Creating advanced features...\n",
      "   ‚úÖ Created 27 total features\n",
      "   ‚úÖ Features prepared: 23 features, 891 samples\n",
      "ü§ñ Training ensemble...\n",
      "ü§ñ Creating quick ensemble...\n",
      "   ‚úÖ Quick ensemble created with 4 diverse models\n",
      "üìà Evaluating with cross-validation...\n",
      "   CV Score: 0.8238 (+/- 0.0453)\n",
      "üéØ Making final predictions...\n",
      "\n",
      "==================================================\n",
      "üéâ QUICK OPTIMIZATION COMPLETE!\n",
      "==================================================\n",
      "üìä Cross-validation score: 0.8238\n",
      "üìà Expected improvement: +0.0305\n",
      "üíæ Saved as: titanic_quick_advanced.csv\n",
      "üìà Predicted survival rate: 36.8%\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# FIXED ADVANCED OPTIMIZATION FOR BETTER KAGGLE SCORE\n",
    "# Handles original Titanic column names correctly\n",
    "# ========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ FIXED ADVANCED OPTIMIZATION FOR KAGGLE LEADERBOARD\")\n",
    "print(\"Target: Push from 79% to 82-85% accuracy\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# COLUMN MAPPING FOR ORIGINAL TITANIC DATA\n",
    "# ========================================\n",
    "\n",
    "def standardize_column_names(df):\n",
    "    \"\"\"Convert original Titanic column names to lowercase for consistency\"\"\"\n",
    "    column_mapping = {\n",
    "        'PassengerId': 'passengerid',\n",
    "        'Survived': 'survived', \n",
    "        'Pclass': 'pclass',\n",
    "        'Name': 'name',\n",
    "        'Sex': 'sex',\n",
    "        'Age': 'age',\n",
    "        'SibSp': 'sibsp',\n",
    "        'Parch': 'parch',\n",
    "        'Ticket': 'ticket',\n",
    "        'Fare': 'fare',\n",
    "        'Cabin': 'cabin',\n",
    "        'Embarked': 'embarked'\n",
    "    }\n",
    "    return df.rename(columns=column_mapping)\n",
    "\n",
    "# ========================================\n",
    "# 1. ADVANCED FEATURE ENGINEERING (FIXED)\n",
    "# ========================================\n",
    "\n",
    "def advanced_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Create more sophisticated features that top Kaggle competitors use\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # First, standardize column names\n",
    "    df = standardize_column_names(df)\n",
    "    \n",
    "    print(\"üîß Creating advanced features...\")\n",
    "    \n",
    "    # Basic feature engineering first\n",
    "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "    df['is_alone'] = (df['family_size'] == 1).astype(int)\n",
    "    df['age'] = df['age'].fillna(df['age'].median())\n",
    "    df['fare'] = df['fare'].fillna(df['fare'].median())\n",
    "    df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])\n",
    "    \n",
    "    # ========================================\n",
    "    # ADVANCED FEATURES\n",
    "    # ========================================\n",
    "    \n",
    "    # 1. Title extraction (more sophisticated)\n",
    "    def extract_title(name):\n",
    "        if pd.isna(name):\n",
    "            return \"\"\n",
    "        title_search = re.search(' ([A-Za-z]+)\\.', str(name))\n",
    "        if title_search:\n",
    "            return title_search.group(1)\n",
    "        return \"\"\n",
    "    \n",
    "    if 'name' in df.columns:\n",
    "        df['title'] = df['name'].apply(extract_title)\n",
    "        \n",
    "        # Group rare titles\n",
    "        title_mapping = {\n",
    "            'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "            'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
    "            'Mlle': 'Miss', 'Countess': 'Rare', 'Ms': 'Miss', 'Lady': 'Rare',\n",
    "            'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Mrs',\n",
    "            'Capt': 'Rare', 'Sir': 'Rare'\n",
    "        }\n",
    "        df['title'] = df['title'].map(title_mapping).fillna('Rare')\n",
    "    else:\n",
    "        df['title'] = 'Unknown'\n",
    "    \n",
    "    # 2. Deck extraction from cabin\n",
    "    if 'cabin' in df.columns:\n",
    "        df['deck'] = df['cabin'].fillna('Unknown').astype(str).str[0]\n",
    "        df['has_cabin'] = (df['cabin'].notna()).astype(int)\n",
    "    else:\n",
    "        df['deck'] = 'Unknown'\n",
    "        df['has_cabin'] = 0\n",
    "    \n",
    "    # 3. Fare per person\n",
    "    df['fare_per_person'] = df['fare'] / df['family_size']\n",
    "    \n",
    "    # 4. Age groups (children, teens, adults, seniors)\n",
    "    df['age_group'] = pd.cut(df['age'], \n",
    "                            bins=[0, 12, 18, 35, 60, 100], \n",
    "                            labels=['Child', 'Teen', 'Adult', 'Middle_Age', 'Senior'])\n",
    "    \n",
    "    # 5. Fare groups (quartiles)\n",
    "    try:\n",
    "        df['fare_group'] = pd.qcut(df['fare'], q=4, labels=['Low', 'Medium', 'High', 'Very_High'], duplicates='drop')\n",
    "    except ValueError:\n",
    "        # If qcut fails due to duplicates, use regular cut\n",
    "        df['fare_group'] = pd.cut(df['fare'], bins=4, labels=['Low', 'Medium', 'High', 'Very_High'])\n",
    "    \n",
    "    # 6. Family survival groups  \n",
    "    df['family_size_group'] = df['family_size'].apply(\n",
    "        lambda x: 'Solo' if x == 1 else 'Small' if x <= 4 else 'Large'\n",
    "    )\n",
    "    \n",
    "    # 7. High-value passenger (first class + high fare)\n",
    "    df['is_high_value'] = ((df['pclass'] == 1) & (df['fare'] > df['fare'].quantile(0.8))).astype(int)\n",
    "    \n",
    "    # 8. Woman and child priority\n",
    "    df['woman_or_child'] = ((df['sex'] == 'female') | (df['age'] < 16)).astype(int)\n",
    "    \n",
    "    # 9. Ticket frequency (shared tickets = families)\n",
    "    if 'ticket' in df.columns:\n",
    "        ticket_counts = df['ticket'].value_counts()\n",
    "        df['ticket_frequency'] = df['ticket'].map(ticket_counts)\n",
    "        df['shared_ticket'] = (df['ticket_frequency'] > 1).astype(int)\n",
    "    else:\n",
    "        df['ticket_frequency'] = 1\n",
    "        df['shared_ticket'] = 0\n",
    "    \n",
    "    # 10. Name length (proxy for social status)\n",
    "    if 'name' in df.columns:\n",
    "        df['name_length'] = df['name'].astype(str).str.len()\n",
    "    else:\n",
    "        df['name_length'] = 0\n",
    "    \n",
    "    # 11. Additional interaction features\n",
    "    df['age_class_interaction'] = df['age'] * df['pclass']\n",
    "    df['fare_class_interaction'] = df['fare'] / df['pclass']\n",
    "    \n",
    "    print(f\"   ‚úÖ Created {df.shape[1]} total features\")\n",
    "    return df\n",
    "\n",
    "# ========================================\n",
    "# 2. QUICK ENSEMBLE (SIMPLIFIED FOR SPEED)\n",
    "# ========================================\n",
    "\n",
    "def create_quick_ensemble():\n",
    "    \"\"\"\n",
    "    Create a fast ensemble that should beat the individual champion\n",
    "    \"\"\"\n",
    "    print(\"ü§ñ Creating quick ensemble...\")\n",
    "    \n",
    "    # Use optimized parameters from your champion\n",
    "    gb1 = GradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3, \n",
    "        min_samples_split=10,\n",
    "        n_estimators=50,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Different random state for diversity\n",
    "    gb2 = GradientBoostingClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=4,\n",
    "        min_samples_split=5, \n",
    "        n_estimators=100,\n",
    "        random_state=123\n",
    "    )\n",
    "    \n",
    "    # Random Forest with good defaults\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=456\n",
    "    )\n",
    "    \n",
    "    # Extra Trees for more diversity\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    et = ExtraTreesClassifier(\n",
    "        n_estimators=150, \n",
    "        max_depth=8,\n",
    "        random_state=789\n",
    "    )\n",
    "    \n",
    "    # Create voting ensemble\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('gb1', gb1),\n",
    "            ('gb2', gb2), \n",
    "            ('rf', rf),\n",
    "            ('et', et)\n",
    "        ],\n",
    "        voting='soft'  # Use probability averaging\n",
    "    )\n",
    "    \n",
    "    print(\"   ‚úÖ Quick ensemble created with 4 diverse models\")\n",
    "    return ensemble\n",
    "\n",
    "# ========================================\n",
    "# 3. MAIN QUICK OPTIMIZATION FUNCTION\n",
    "# ========================================\n",
    "\n",
    "def run_quick_optimization():\n",
    "    \"\"\"\n",
    "    Run a faster version of advanced optimization\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ RUNNING QUICK OPTIMIZATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Load data (using your existing train_data and test_data)\n",
    "        print(\"üìä Processing data...\")\n",
    "        \n",
    "        # Apply advanced feature engineering\n",
    "        train_advanced = advanced_feature_engineering(train_data)\n",
    "        test_advanced = advanced_feature_engineering(test_data)\n",
    "        \n",
    "        # Prepare features\n",
    "        # Drop non-predictive columns\n",
    "        drop_columns = ['passengerid', 'name', 'ticket', 'cabin']\n",
    "        \n",
    "        X_train_adv = train_advanced.drop(columns=drop_columns + ['survived'], errors='ignore')\n",
    "        y_train_adv = train_advanced['survived']\n",
    "        X_test_adv = test_advanced.drop(columns=drop_columns + ['survived'], errors='ignore')\n",
    "        \n",
    "        # Handle categorical variables\n",
    "        categorical_cols = X_train_adv.select_dtypes(include=['object', 'category']).columns\n",
    "        for col in categorical_cols:\n",
    "            # Simple label encoding for categorical variables\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            # Fit on combined data to handle unseen categories\n",
    "            combined_values = pd.concat([X_train_adv[col], X_test_adv[col]]).astype(str)\n",
    "            le.fit(combined_values)\n",
    "            \n",
    "            X_train_adv[col] = le.transform(X_train_adv[col].astype(str))\n",
    "            X_test_adv[col] = le.transform(X_test_adv[col].astype(str))\n",
    "        \n",
    "        print(f\"   ‚úÖ Features prepared: {X_train_adv.shape[1]} features, {X_train_adv.shape[0]} samples\")\n",
    "        \n",
    "        # Create and train ensemble\n",
    "        print(\"ü§ñ Training ensemble...\")\n",
    "        ensemble = create_quick_ensemble()\n",
    "        ensemble.fit(X_train_adv, y_train_adv)\n",
    "        \n",
    "        # Cross-validation score\n",
    "        print(\"üìà Evaluating with cross-validation...\")\n",
    "        cv_scores = cross_val_score(ensemble, X_train_adv, y_train_adv, cv=5, scoring='accuracy')\n",
    "        print(f\"   CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "        \n",
    "        # Make predictions\n",
    "        print(\"üéØ Making final predictions...\")\n",
    "        predictions = ensemble.predict(X_test_adv)\n",
    "        \n",
    "        # Create submission\n",
    "        submission = pd.DataFrame({\n",
    "            'PassengerId': test_data['PassengerId'],\n",
    "            'Survived': predictions.astype(int)\n",
    "        })\n",
    "        \n",
    "        submission.to_csv('titanic_quick_advanced.csv', index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"üéâ QUICK OPTIMIZATION COMPLETE!\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üìä Cross-validation score: {cv_scores.mean():.4f}\")\n",
    "        print(f\"üìà Expected improvement: {cv_scores.mean() - 0.7933:+.4f}\")\n",
    "        print(f\"üíæ Saved as: titanic_quick_advanced.csv\")\n",
    "        print(f\"üìà Predicted survival rate: {predictions.mean():.1%}\")\n",
    "        \n",
    "        return ensemble, cv_scores.mean(), submission\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in quick optimization: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "# ========================================\n",
    "# RUN THE QUICK OPTIMIZATION\n",
    "# ========================================\n",
    "\n",
    "print(\"üöÄ Starting Quick Advanced Optimization...\")\n",
    "print(\"This will take 5-10 minutes and should improve your score!\")\n",
    "\n",
    "# Run the optimization\n",
    "quick_model, quick_score, quick_submission = run_quick_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460a479-8d3c-4b5f-af71-29ab5b18d05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
